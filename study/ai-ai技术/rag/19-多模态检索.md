# 多模态检索

**详细实现：**
```python
class MultimodalRetriever:
    def __init__(
        self,
        text_encoder,
        image_encoder,
        fusion_model
    ):
        self.text_encoder = text_encoder
        self.image_encoder = image_encoder
        self.fusion_model = fusion_model
        
    def retrieve(
        self,
        query: str,
        top_k: int = 5,
        modalities: List[str] = ['text', 'image']
    ) -> List[Document]:
        # 1. 编码查询
        query_embedding = self.text_encoder.encode(query)
        
        # 2. 多模态检索
        results = {}
        if 'text' in modalities:
            text_results = self._retrieve_text(query_embedding)
            results['text'] = text_results
            
        if 'image' in modalities:
            image_results = self._retrieve_images(query_embedding)
            results['image'] = image_results
            
        # 3. 特征融合
        fused_results = self._fuse_results(results, query)
        
        # 4. 重排序
        ranked_results = self._rank_multimodal_results(
            fused_results, query)
        
        return ranked_results[:top_k]
    
    def _fuse_results(
        self,
        results: Dict[str, List[Document]],
        query: str
    ) -> List[Document]:
        # 使用fusion model合并不同模态的特征
        fused_docs = []
        
        for text_doc in results.get('text', []):
            for image_doc in results.get('image', []):
                if self._are_related(text_doc, image_doc):
                    fused_doc = self._create_fused_document(
                        text_doc, image_doc)
                    fused_docs.append(fused_doc)
                    
        return fused_docs
```

**优化策略：**
1. 跨模态对齐
   ```python
   class CrossModalAligner:
       def align_embeddings(
           self,
           text_embeds: torch.Tensor,
           image_embeds: torch.Tensor
       ) -> Tuple[torch.Tensor, torch.Tensor]:
           # 使用对比学习对齐不同模态的特征空间
           aligned_text = self.text_projector(text_embeds)
           aligned_image = self.image_projector(image_embeds)
           
           # 计算对比损失
           loss = self.contrastive_loss(
               aligned_text, aligned_image)
           
           return aligned_text, aligned_image
   ```

2. 多模态索引优化
   ```python
   class MultimodalIndex:
       def __init__(self):
           self.text_index = FAISS(768)  # 文本特征维度
           self.image_index = FAISS(512)  # 图像特征维度
           self.cross_modal_index = FAISS(1024)  # 融合特征维度
           
       def build_index(
           self,
           documents: List[Document]
       ):
           for doc in documents:
               # 提取并索引文本特征
               if doc.has_text:
                   text_features = self.text_encoder(doc.text)
                   self.text_index.add(text_features)
                   
               # 提取并索引图像特征
               if doc.has_image:
                   image_features = self.image_encoder(doc.image)
                   self.image_index.add(image_features)
                   
               # 构建并索引融合特征
               if doc.has_text and doc.has_image:
                   fused_features = self.fusion_model(
                       text_features, image_features)
                   self.cross_modal_index.add(fused_features)
   ``` 