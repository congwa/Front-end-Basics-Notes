# 多方面过滤


一句话总结： 应用各种过滤技术来细化和提高检索结果的质量（元数据过滤、相似度阈值、内容过滤、多样性过滤）

## 多方位过滤

### 概览

应用各种过滤技术来细化和提高检索结果的质量。

### 实施

1. 元数据过滤

   - 根据日期、来源、作者或文档类型等属性应用过滤器

2. 相似度阈值

   - 设置相关性分数的阈值，以仅保留最相关的结果

3. 内容过滤  

   - 删除与特定内容标准或基本关键字不匹配的结果

4. 多样性过滤

   - 通过过滤掉接近重复的条目来确保结果多样性

```py

import numpy as np
# 计算两个向量之间的余弦夹角的余弦值来衡量相似度
from sklearn.metrics.pairwise import cosine_similarity

# 示例数据
documents = [
    {"id": 1, "date": "2025-01-01", "source": "source1", "author": "author1", "type": "report", "content": "AI is transforming industries.", "vector": [0.1, 0.3, 0.5]},
    {"id": 2, "date": "2024-12-30", "source": "source2", "author": "author2", "type": "blog", "content": "Machine learning is a subset of AI.", "vector": [0.1, 0.3, 0.51]},
    {"id": 3, "date": "2023-11-15", "source": "source3", "author": "author3", "type": "paper", "content": "Deep learning techniques are revolutionary.", "vector": [0.2, 0.4, 0.6]},
    {"id": 4, "date": "2023-12-01", "source": "source1", "author": "author4", "type": "report", "content": "AI and robotics are evolving together.", "vector": [0.3, 0.5, 0.7]},
]

query_vector = [0.15, 0.35, 0.55]  # 示例查询向量
similarity_threshold = 0.95  # 相似度阈值
essential_keywords = ["AI", "learning"]  # 关键词过滤标准

# 1. 元数据过滤
def metadata_filtering(docs, allowed_sources, allowed_types):
    return [doc for doc in docs if doc["source"] in allowed_sources and doc["type"] in allowed_types]

# 2. 相似度阈值过滤
def similarity_filtering(docs, query_vec, threshold):
    results = []
    for doc in docs:
        similarity = cosine_similarity([doc["vector"]], [query_vec])[0][0]
        if similarity >= threshold:
            doc["similarity"] = similarity
            results.append(doc)
    return results

# 3. 内容过滤
def content_filtering(docs, keywords):
    return [doc for doc in docs if any(keyword in doc["content"] for keyword in keywords)]

# 4. 多样性过滤（去重）
def diversity_filtering(docs, diversity_threshold=0.99):
    results = []
    seen_vectors = []
    for doc in docs:
        if all(cosine_similarity([doc["vector"]], [v])[0][0] < diversity_threshold for v in seen_vectors):
            results.append(doc)
            seen_vectors.append(doc["vector"])
    return results

# 过滤步骤
def multi_faceted_filtering(docs, query_vec):
    # 元数据过滤
    filtered_docs = metadata_filtering(docs, allowed_sources=["source1", "source2"], allowed_types=["report", "blog"])
    print("After Metadata Filtering:", [doc["id"] for doc in filtered_docs])

    # 相似度阈值过滤
    filtered_docs = similarity_filtering(filtered_docs, query_vec, similarity_threshold)
    print("After Similarity Filtering:", [doc["id"] for doc in filtered_docs])

    # 内容过滤
    filtered_docs = content_filtering(filtered_docs, essential_keywords)
    print("After Content Filtering:", [doc["id"] for doc in filtered_docs])

    # 多样性过滤
    filtered_docs = diversity_filtering(filtered_docs, diversity_threshold=0.95)
    print("After Diversity Filtering:", [doc["id"] for doc in filtered_docs])

    return filtered_docs

# 运行过滤流程
final_results = multi_faceted_filtering(documents, query_vector)

# 打印最终结果
print("\nFinal Filtered Results:")
for doc in final_results:
    print(doc)


```
