# åˆ†å— - å‘½é¢˜åˆ†å—

> ğŸ·ï¸ æŠ€æœ¯åˆ†ç±»: åŸºç¡€RAGæŠ€æœ¯
> 
> ğŸ”— ç›¸å…³æŠ€æœ¯: ç®€å•RAGã€è¯­ä¹‰åˆ†å—ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†å—

## æŠ€æœ¯æ¦‚è¿°

å‘½é¢˜åˆ†å— (Proposition-based Chunking) æ˜¯ä¸€ç§åŸºäºè¯­ä¹‰å‘½é¢˜çš„æ–‡æ¡£åˆ†å—ç­–ç•¥,é€šè¿‡è¯†åˆ«å’Œæå–æ–‡æœ¬ä¸­çš„æ ¸å¿ƒå‘½é¢˜æ¥è¿›è¡Œåˆ†å—,ä»¥æé«˜æ£€ç´¢çš„å‡†ç¡®æ€§å’Œè¯­ä¹‰ç›¸å…³æ€§ã€‚

## å…³é”®æ­¥éª¤

ç³»ç»Ÿå°†è¾“å…¥æ–‡æœ¬åˆ†è§£ä¸ºåŸå­çš„ã€äº‹å®çš„ã€ç‹¬ç«‹çš„ã€ç®€æ´çš„å‘½é¢˜ï¼Œå°†å‘½é¢˜ç¼–ç åˆ°å‘é‡å­˜å‚¨ä¸­ï¼Œä»¥ä¾¿ä»¥åç”¨äºæ£€ç´¢ã€‚

ä¸»è¦ç»„ä»¶åŒ…æ‹¬:

1. æ–‡æ¡£åˆ†å—
- å°†æ–‡æ¡£åˆ†å‰²æˆå¯ç®¡ç†çš„éƒ¨åˆ†ä»¥è¿›è¡Œåˆ†æ

2. å‘½é¢˜ç”Ÿæˆ 
- ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹å°†æ–‡æ¡£å—åˆ†è§£ä¸ºäº‹å®ã€ç‹¬ç«‹çš„å‘½é¢˜

3. å‘½é¢˜è´¨é‡æ£€æŸ¥
- æ ¹æ®å‡†ç¡®æ€§ã€æ¸…æ™°åº¦ã€å®Œæ•´æ€§å’Œç®€æ´æ€§è¯„ä¼°ç”Ÿæˆçš„å‘½é¢˜

4. åµŒå…¥å’Œå‘é‡å­˜å‚¨
- å°†å‘½é¢˜å’Œè¾ƒå¤§çš„æ–‡æ¡£å—åµŒå…¥åˆ°å‘é‡å­˜å‚¨ä¸­ä»¥è¿›è¡Œé«˜æ•ˆæ£€ç´¢

5. æ£€ç´¢å’Œæ¯”è¾ƒ
- ä½¿ç”¨ä¸åŒçš„æŸ¥è¯¢å¤§å°æµ‹è¯•æ£€ç´¢ç³»ç»Ÿ
- å°†åŸºäºå‘½é¢˜çš„æ¨¡å‹ç»“æœä¸åŸºäºå—çš„æ¨¡å‹è¿›è¡Œæ¯”è¾ƒ
## å‘½é¢˜åˆ†å—ä¸ç®€å•åˆ†å—çš„æ¯”è¾ƒ

| æ¯”è¾ƒç»´åº¦ | åŸºäºå‘½é¢˜çš„æ£€ç´¢ | ç®€å•å—æ£€ç´¢ |
|---------|--------------|------------|
| å“åº”ç²¾ç¡®åº¦ | é«˜ï¼šæä¾›é›†ä¸­ä¸”ç›´æ¥çš„ç­”æ¡ˆ | ä¸­ï¼šæä¾›æ›´å¤šä¸Šä¸‹æ–‡ä½†å¯èƒ½åŒ…å«ä¸ç›¸å…³ä¿¡æ¯ |
| æ¸…æ™°ç®€æ´æ€§ | é«˜ï¼šæ¸…æ™°ç®€æ´ï¼Œé¿å…å†—ä½™ç»†èŠ‚ | ä¸­ï¼šå†…å®¹å…¨é¢ä½†å¯èƒ½è¿‡äºå†—é•¿ |
| ä¸Šä¸‹æ–‡ä¸°å¯Œåº¦ | ä½ï¼šä¸“æ³¨äºå…·ä½“å‘½é¢˜ï¼Œå¯èƒ½ç¼ºä¹èƒŒæ™¯ | é«˜ï¼šæä¾›å……è¶³çš„ä¸Šä¸‹æ–‡å’Œç»†èŠ‚ |
| å†…å®¹å®Œæ•´æ€§ | ä½ï¼šå¯èƒ½å¿½ç•¥æ›´å¹¿æ³›çš„èƒŒæ™¯ä¿¡æ¯ | é«˜ï¼šæä¾›æ›´å®Œæ•´çš„ä¿¡æ¯è§†è§’ |
| å™è¿°æµç•…æ€§ | ä¸­ï¼šå†…å®¹å¯èƒ½è¾ƒä¸ºé›¶æ•£ | é«˜ï¼šä¿æŒåŸæ–‡çš„é€»è¾‘è¿è´¯æ€§ |
| ä¿¡æ¯è´Ÿè½½ | ä½ï¼šä¸æ˜“é€ æˆä¿¡æ¯è¿‡è½½ | é«˜ï¼šå¯èƒ½å¯¼è‡´ä¿¡æ¯è¶…è½½ |
| é€‚ç”¨åœºæ™¯ | é€‚åˆå¿«é€Ÿäº‹å®æŸ¥è¯¢ | é€‚åˆéœ€æ·±å…¥ç†è§£çš„å¤æ‚æŸ¥è¯¢ |
| æ£€ç´¢æ•ˆç‡ | é«˜ï¼šå¿«é€Ÿå®šä½ç›®æ ‡ä¿¡æ¯ | ä¸­ï¼šéœ€è¦æ›´å¤šç­›é€‰å·¥ä½œ |
| ç­”æ¡ˆç²¾å‡†åº¦ | é«˜ï¼šå›ç­”ç²¾å‡†ä¸”æœ‰é’ˆå¯¹æ€§ | ä¸­ï¼šç­”æ¡ˆå¯èƒ½ä¸å¤Ÿèšç„¦ |

## åº”ç”¨åœºæ™¯

- ğŸ“– é•¿æ–‡æ¡£å¤„ç†
- ğŸ“‘ å­¦æœ¯è®ºæ–‡åˆ†æ
- ğŸ“‹ æŠ€æœ¯æ–‡æ¡£ç®¡ç†
- ğŸ“ ä¸“åˆ©æ–‡çŒ®å¤„ç†

## è¯¦ç»†å®ç°

```python
from typing import List, Dict
from spacy import Language
from transformers import Pipeline
import spacy

class PropositionChunker:
    def __init__(
        self,
        nlp: Language = None,
        proposition_extractor: Pipeline = None,
        min_prop_length: int = 10,    # æœ€å°å‘½é¢˜é•¿åº¦
        max_props_per_chunk: int = 5  # æ¯å—æœ€å¤§å‘½é¢˜æ•°
    ):
        """
        åˆå§‹åŒ–å‘½é¢˜åˆ†å—å™¨
        Args:
            nlp: SpaCyè¯­è¨€æ¨¡å‹
            proposition_extractor: å‘½é¢˜æå–æ¨¡å‹
            min_prop_length: æœ€å°å‘½é¢˜é•¿åº¦
            max_props_per_chunk: æ¯å—æœ€å¤§å‘½é¢˜æ•°
        """
        self.nlp = nlp or spacy.load("zh_core_web_trf")
        self.proposition_extractor = proposition_extractor
        self.min_prop_length = min_prop_length
        self.max_props_per_chunk = max_props_per_chunk
        
    def chunk_document(
        self,
        document: str
    ) -> List[Dict]:
        """
        åŸºäºå‘½é¢˜çš„æ–‡æ¡£åˆ†å—
        Args:
            document: è¾“å…¥æ–‡æ¡£
        Returns:
            åŒ…å«å‘½é¢˜ä¿¡æ¯çš„æ–‡æ¡£å—åˆ—è¡¨
        """
        # 1. æ–‡æ¡£é¢„å¤„ç†
        doc = self.nlp(document)
        
        # 2. æå–å‘½é¢˜
        propositions = self._extract_propositions(doc)
        
        # 3. å‘½é¢˜è¿‡æ»¤å’Œè§„èŒƒåŒ–
        valid_props = self._filter_propositions(propositions)
        
        # 4. å‘½é¢˜èšç±»
        prop_clusters = self._cluster_propositions(valid_props)
        
        # 5. ç”Ÿæˆæœ€ç»ˆåˆ†å—
        chunks = self._create_chunks_from_clusters(prop_clusters)
        
        return chunks
        
    def _extract_propositions(
        self,
        doc: Language
    ) -> List[Dict]:
        """
        ä»æ–‡æ¡£ä¸­æå–å‘½é¢˜
        """
        propositions = []
        
        # ä½¿ç”¨ä¾å­˜å¥æ³•åˆ†ææå–å‘½é¢˜
        for sent in doc.sents:
            # æ‰¾åˆ°ä¸»è°“å…³ç³»
            for token in sent:
                if token.dep_ == "ROOT":
                    # æ„å»ºå‘½é¢˜
                    prop = self._build_proposition(token)
                    if prop:
                        propositions.append(prop)
                        
        return propositions
        
    def _build_proposition(
        self,
        root_token
    ) -> Dict:
        """
        åŸºäºæ ¹èŠ‚ç‚¹æ„å»ºå‘½é¢˜
        """
        # æå–ä¸»è¯­
        subject = self._extract_subject(root_token)
        
        # æå–è°“è¯­
        predicate = self._extract_predicate(root_token)
        
        # æå–å®¾è¯­
        object_ = self._extract_object(root_token)
        
        # æå–ä¿®é¥°è¯­
        modifiers = self._extract_modifiers(root_token)
        
        return {
            'subject': subject,
            'predicate': predicate,
            'object': object_,
            'modifiers': modifiers,
            'text': self._combine_proposition_parts(
                subject, predicate, object_, modifiers)
        }
```

## æ ¸å¿ƒç»„ä»¶

1. å‘½é¢˜æå–å™¨
```python
class PropositionExtractor:
    def extract_propositions(
        self,
        text: str
    ) -> List[Dict]:
        """
        æå–æ–‡æœ¬ä¸­çš„å‘½é¢˜
        """
        # å¥æ³•åˆ†æ
        doc = self.nlp(text)
        
        # æå–ä¸»è¦å‘½é¢˜
        main_props = self._extract_main_propositions(doc)
        
        # æå–ä»å±å‘½é¢˜
        sub_props = self._extract_subordinate_propositions(doc)
        
        # å»ºç«‹å‘½é¢˜å…³ç³»
        prop_relations = self._build_proposition_relations(
            main_props,
            sub_props
        )
        
        return prop_relations
```

## æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | å‘½é¢˜åˆ†å— | å›ºå®šé•¿åº¦åˆ†å— | æ”¹è¿› |
|------|----------|--------------|------|
| è¯­ä¹‰å®Œæ•´æ€§ | 95% | 60% | +35% |
| æ£€ç´¢å‡†ç¡®ç‡ | 92% | 75% | +17% |
| ä¸Šä¸‹æ–‡ä¿æŒ | 94% | 70% | +24% |
| å¤„ç†æ—¶é—´ | 3.0s | 1.0s | +2.0s |

## æœ€ä½³å®è·µ

1. å‘½é¢˜æå–
   - ä½¿ç”¨é«˜è´¨é‡è¯­è¨€æ¨¡å‹
   - å¤„ç†å¤æ‚å¥å¼
   - ä¿æŒå‘½é¢˜å®Œæ•´æ€§

2. åˆ†å—ç­–ç•¥
   - å¹³è¡¡å—å¤§å°å’Œè¯­ä¹‰
   - å¤„ç†äº¤å‰å¼•ç”¨
   - ç»´æŠ¤å‘½é¢˜å…³ç³»

3. æ€§èƒ½ä¼˜åŒ–
   - å¹¶è¡Œå¤„ç†é•¿æ–‡æ¡£
   - ç¼“å­˜å¸¸è§å‘½é¢˜
   - ä¼˜åŒ–è¯­è¨€æ¨¡å‹è°ƒç”¨

## ä½¿ç”¨ç¤ºä¾‹

```python
# åˆå§‹åŒ–å‘½é¢˜åˆ†å—å™¨
chunker = PropositionChunker(
    min_prop_length=10,
    max_props_per_chunk=5
)

# ç¤ºä¾‹æ–‡æ¡£
document = """
äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»ã€‚æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯,
å®ƒèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ã€‚æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯,
å·²ç»åœ¨è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚
"""

# æ‰§è¡Œåˆ†å—
chunks = chunker.chunk_document(document)

# åˆ†æç»“æœ
for chunk in chunks:
    print("å‘½é¢˜é›†åˆ:")
    for prop in chunk['propositions']:
        print(f"- ä¸»è¯­: {prop['subject']}")
        print(f"  è°“è¯­: {prop['predicate']}")
        print(f"  å®¾è¯­: {prop['object']}")
    print("---")
```

## æ³¨æ„äº‹é¡¹

1. è¯­è¨€å¤„ç†
   - å¤„ç†æ­§ä¹‰æƒ…å†µ
   - è§£å†³å…±æŒ‡é—®é¢˜
   - å¤„ç†ç‰¹æ®Šè¯­æ³•

2. å‘½é¢˜è´¨é‡
   - éªŒè¯å‘½é¢˜å®Œæ•´æ€§
   - å¤„ç†å¤æ‚ä»å¥
   - ä¿æŒè¯­ä¹‰å‡†ç¡®

3. æ‰©å±•æ€§è€ƒè™‘
   - æ”¯æŒå¤šè¯­è¨€å¤„ç†
   - å¤„ç†é¢†åŸŸç‰¹å®šæ–‡æœ¬
   - é€‚åº”ä¸åŒæ–‡æ¡£ç±»å‹

## æ‰©å±•é˜…è¯»

- [è¯­ä¹‰åˆ†å—æŠ€æœ¯ç»¼è¿°](https://diamantai.substack.com/p/the-propositions-method-enhancing?r=336pe4&utm_campaign=post&utm_medium=web&triedRedirect=true)
- [SpaCyä¾å­˜å¥æ³•åˆ†æ](https://spacy.io/usage/linguistic-features#dependency-parse)