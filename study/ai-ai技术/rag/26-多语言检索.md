# å¤šè¯­è¨€æ£€ç´¢

> ğŸ·ï¸ æŠ€æœ¯åˆ†ç±»: é«˜çº§æ£€ç´¢æŠ€æœ¯
> 
> ğŸ”— ç›¸å…³æŠ€æœ¯: è·¨è¯­è¨€æ£€ç´¢ã€è¯­ä¹‰æ£€ç´¢ã€è‡ªé€‚åº”æ£€ç´¢

## æŠ€æœ¯æ¦‚è¿°

å¤šè¯­è¨€æ£€ç´¢é€šè¿‡è·¨è¯­è¨€æ¨¡å‹å’Œç¿»è¯‘æŠ€æœ¯,å®ç°å¯¹ä¸åŒè¯­è¨€æ–‡æ¡£çš„ç»Ÿä¸€æ£€ç´¢å’Œé—®ç­”èƒ½åŠ›ã€‚

## åº”ç”¨åœºæ™¯

- ğŸŒ è·¨è¯­è¨€çŸ¥è¯†åº“
- ğŸ” å¤šè¯­è¨€æœç´¢å¼•æ“
- ğŸ’¬ å›½é™…åŒ–å®¢æœç³»ç»Ÿ
- ğŸ“š å¤šè¯­è¨€æ–‡æ¡£ç®¡ç†

## è¯¦ç»†å®ç°

```python
class MultilingualRetriever:
    def __init__(
        self,
        base_retriever,     # åŸºç¡€æ£€ç´¢å™¨
        translator,         # ç¿»è¯‘å™¨
        lang_detector,      # è¯­è¨€æ£€æµ‹å™¨
        cross_lingual_model # è·¨è¯­è¨€æ¨¡å‹
    ):
        self.base_retriever = base_retriever
        self.translator = translator
        self.lang_detector = lang_detector
        self.cross_lingual_model = cross_lingual_model
        
    def retrieve(
        self,
        query: str,
        target_langs: List[str] = None,
        top_k: int = 5
    ) -> List[Document]:
        """
        å¤šè¯­è¨€æ£€ç´¢å®ç°
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            target_langs: ç›®æ ‡è¯­è¨€åˆ—è¡¨
            top_k: è¿”å›ç»“æœæ•°é‡
        Returns:
            æ£€ç´¢åˆ°çš„å¤šè¯­è¨€æ–‡æ¡£åˆ—è¡¨
        """
        # 1. æ£€æµ‹æŸ¥è¯¢è¯­è¨€
        query_lang = self.lang_detector.detect(query)
        
        # 2. ç¡®å®šç›®æ ‡è¯­è¨€
        if not target_langs:
            target_langs = self._determine_relevant_langs(query)
        
        # 3. è·¨è¯­è¨€æŸ¥è¯¢æ‰©å±•
        translated_queries = self._translate_query(
            query, query_lang, target_langs)
        
        # 4. å¤šè¯­è¨€æ£€ç´¢
        all_results = []
        for lang, trans_query in translated_queries.items():
            # æ‰§è¡Œè¯­è¨€ç‰¹å®šæ£€ç´¢
            lang_results = self.base_retriever.retrieve(
                trans_query,
                language=lang
            )
            all_results.extend(lang_results)
        
        # 5. è·¨è¯­è¨€é‡æ’åº
        unified_results = self._cross_lingual_rerank(
            all_results, query, query_lang)
        
        return unified_results[:top_k]
```

## æ ¸å¿ƒç»„ä»¶

1. è·¨è¯­è¨€åµŒå…¥
```python
class CrossLingualEmbedder:
    def __init__(self, model_name="xlm-roberta-base"):
        self.model = AutoModel.from_pretrained(model_name)
        
    def embed_multilingual(
        self,
        texts: List[str],
        languages: List[str]
    ) -> torch.Tensor:
        """
        ç”Ÿæˆè·¨è¯­è¨€æ–‡æœ¬åµŒå…¥
        """
        embeddings = []
        
        for text, lang in zip(texts, languages):
            # åº”ç”¨è¯­è¨€ç‰¹å®šçš„é¢„å¤„ç†
            processed_text = self._preprocess_text(text, lang)
            
            # è·å–è·¨è¯­è¨€åµŒå…¥
            embedding = self.model.encode(
                processed_text,
                language=lang
            )
            embeddings.append(embedding)
            
        return torch.stack(embeddings)
```

2. è¯­è¨€å¤„ç†å™¨
```python
class LanguageHandler:
    def __init__(self):
        self.lang_detector = fasttext.load_model('lid.176.bin')
        self.lang_specific_tokenizers = {}
        
    def process_text(
        self,
        text: str,
        target_lang: str = None
    ) -> Tuple[str, str]:
        """
        æ–‡æœ¬è¯­è¨€å¤„ç†ä¸è½¬æ¢
        """
        # æ£€æµ‹è¯­è¨€
        detected_lang = self._detect_language(text)
        
        # è·å–è¯­è¨€ç‰¹å®šçš„å¤„ç†å™¨
        processor = self._get_language_processor(detected_lang)
        
        # åº”ç”¨è¯­è¨€ç‰¹å®šçš„å¤„ç†
        processed_text = processor.process(text)
        
        # å¦‚æœéœ€è¦,è¿›è¡Œç¿»è¯‘
        if target_lang and detected_lang != target_lang:
            processed_text = self.translator.translate(
                processed_text,
                source_lang=detected_lang,
                target_lang=target_lang
            )
            
        return processed_text, detected_lang
```

## æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | å¤šè¯­è¨€RAG | å•è¯­è¨€RAG | æ”¹è¿› |
|------|-----------|-----------|------|
| è·¨è¯­è¨€å‡†ç¡®ç‡ | 87% | 45% | +42% |
| è¯­ä¹‰ä¿æŒåº¦ | 92% | 70% | +22% |
| æ£€ç´¢å¬å›ç‡ | 85% | 60% | +25% |
| å¹³å‡å»¶è¿Ÿ | 3.5s | 2.0s | +1.5s |

## æœ€ä½³å®è·µ

1. è¯­è¨€å¤„ç†
   - ä½¿ç”¨ä¸“ä¸šçš„è¯­è¨€æ£€æµ‹å·¥å…·
   - é’ˆå¯¹ä¸åŒè¯­è¨€ä¼˜åŒ–åˆ†è¯
   - å¤„ç†ç‰¹æ®Šå­—ç¬¦å’Œç¼–ç 

2. ç¿»è¯‘ç­–ç•¥
   - å®ç°æŸ¥è¯¢ç¿»è¯‘ç¼“å­˜
   - ä½¿ç”¨é¢†åŸŸç‰¹å®šç¿»è¯‘æ¨¡å‹
   - ä¿æŒå…³é”®æœ¯è¯­ä¸€è‡´æ€§

3. ç´¢å¼•ä¼˜åŒ–
   - æ„å»ºå¤šè¯­è¨€å‘é‡ç´¢å¼•
   - å®ç°è¯­è¨€ç‰¹å®šçš„ç›¸ä¼¼åº¦è®¡ç®—
   - ä¼˜åŒ–è·¨è¯­è¨€æ£€ç´¢æ€§èƒ½

## ä½¿ç”¨ç¤ºä¾‹

```python
# åˆå§‹åŒ–å¤šè¯­è¨€æ£€ç´¢ç³»ç»Ÿ
retriever = MultilingualRetriever(
    base_retriever=BaseRetriever(),
    translator=Translator(model="opus-mt-multilingual"),
    lang_detector=LanguageDetector(),
    cross_lingual_model=XLMRoberta("xlm-roberta-large")
)

# æ·»åŠ å¤šè¯­è¨€æ–‡æ¡£
documents = [
    Document("AI is transforming our world", lang="en"),
    Document("L'IA transforme notre monde", lang="fr"),
    Document("äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ä¸–ç•Œ", lang="zh")
]
retriever.index_documents(documents)

# å¤šè¯­è¨€æŸ¥è¯¢ç¤ºä¾‹
query = "What are the impacts of AI?"
results = retriever.retrieve(
    query,
    target_langs=["en", "fr", "zh"],
    top_k=3
)
```

## æ³¨æ„äº‹é¡¹

1. è¯­è¨€ç‰¹æ€§å¤„ç†
   - æ³¨æ„è¯­è¨€ç‰¹å®šçš„è¯­æ³•ç»“æ„
   - å¤„ç†è¯åºå·®å¼‚
   - è€ƒè™‘æ–‡åŒ–èƒŒæ™¯å·®å¼‚

2. èµ„æºæ¶ˆè€—
   - ç›‘æ§ç¿»è¯‘APIä½¿ç”¨
   - ä¼˜åŒ–æ¨¡å‹åŠ è½½
   - å®ç°ç»“æœç¼“å­˜

3. è´¨é‡æ§åˆ¶
   - å®šæœŸè¯„ä¼°ç¿»è¯‘è´¨é‡
   - ç›‘æ§è·¨è¯­è¨€åŒ¹é…å‡†ç¡®åº¦
   - æ”¶é›†ç”¨æˆ·åé¦ˆ

## æ‰©å±•é˜…è¯»

- [è·¨è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹](https://example.com)
- [å¤šè¯­è¨€æ£€ç´¢è¯„ä¼°](https://example.com)
- [è¯­è¨€æ£€æµ‹æœ€ä½³å®è·µ](https://example.com)