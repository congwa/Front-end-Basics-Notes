# 高级检索方法 - 融合检索

## 核心机制

1. 基于向量的相似度检索 (vectorstore.similarity_search_with_score) 和基于BM25的关键词匹配检索（bm25.get_scores）分别执行。
2. 将两个检索结果的得分进行归一化处理，然后加权融合：
    - 向量检索得分乘以 alpha 权重。
    - BM25得分乘以 1-alpha 权重。
3. 最终计算得到每个文档的融合得分，并返回排名前 k 的文档

4. 展示检索结果：
    - 对返回的文档内容进行展示，展示结果通常是与查询最相关的 k 个文档内容。

```py
import os
import sys
from dotenv import load_dotenv
from langchain.docstore.document import Document
from typing import List
from rank_bm25 import BM25Okapi
import numpy as np

# 将父目录添加到路径
sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))
from helper_functions import *
from evaluation.evalute_rag import *

# 加载环境变量
load_dotenv()
os.environ["OPENAI_API_KEY"] = os.getenv('OPENAI_API_KEY')


# 将PDF编码为向量存储并返回拆分的文档
def 编码PDF并获取拆分文档(路径, chunk_size=1000, chunk_overlap=200):
    """
    使用OpenAI嵌入对PDF书籍进行编码并创建向量存储。

    参数：
        路径: PDF文件的路径。
        chunk_size: 每个文本块的大小。
        chunk_overlap: 连续块之间的重叠量。

    返回：
        包含编码书籍内容的FAISS向量存储。
    """
    loader = PyPDFLoader(路径)
    documents = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len
    )
    texts = text_splitter.split_documents(documents)
    cleaned_texts = replace_t_with_space(texts)
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)

    return vectorstore, cleaned_texts


# 为关键词检索创建BM25索引
def 创建BM25索引(documents: List[Document]) -> BM25Okapi:
    """
    从给定文档创建BM25索引。

    参数：
        documents (List[Document]): 要索引的文档列表。

    返回：
        BM25Okapi: 可用于BM25评分的索引。
    """
    tokenized_docs = [doc.page_content.split() for doc in documents]
    return BM25Okapi(tokenized_docs)


# 融合检索：结合基于关键词（BM25）和基于向量的检索
def 融合检索(vectorstore, bm25, query: str, k: int = 5, alpha: float = 0.5) -> List[Document]:
    """
    执行融合检索，结合关键词检索（BM25）和向量检索。

    参数：
        vectorstore (VectorStore): 包含文档的向量存储。
        bm25 (BM25Okapi): 预先计算的BM25索引。
        query (str): 查询字符串。
        k (int): 要检索的文档数量。
        alpha (float): 向量检索得分的权重（1-alpha 为BM25得分的权重）。

    返回：
        List[Document]: 基于组合评分的前k个文档。
    """
    all_docs = vectorstore.similarity_search("", k=vectorstore.index.ntotal)
    bm25_scores = bm25.get_scores(query.split())
    vector_results = vectorstore.similarity_search_with_score(query, k=len(all_docs))

    vector_scores = np.array([score for _, score in vector_results])
    vector_scores = 1 - (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores))
    bm25_scores = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores))

    combined_scores = alpha * vector_scores + (1 - alpha) * bm25_scores
    sorted_indices = np.argsort(combined_scores)[::-1]

    return [all_docs[i] for i in sorted_indices[:k]]


class 融合检索RAG:
    def __init__(self, 路径: str, chunk_size: int = 1000, chunk_overlap: int = 200):
        """
        初始化融合检索RAG类，设置向量存储和BM25索引。

        参数：
            路径 (str): PDF文件的路径。
            chunk_size (int): 每个文本块的大小。
            chunk_overlap (int): 连续块之间的重叠量。
        """
        self.vectorstore, self.cleaned_texts = 编码PDF并获取拆分文档(路径, chunk_size, chunk_overlap)
        self.bm25 = 创建BM25索引(self.cleaned_texts)

    def 运行(self, query: str, k: int = 5, alpha: float = 0.5):
        """
        对给定的查询执行融合检索。

        参数：
            query (str): 搜索查询。
            k (int): 要检索的文档数量。
            alpha (float): 向量检索与BM25检索的权重。

        返回：
            List[Document]: 检索到的前k个文档。
        """
        top_docs = 融合检索(self.vectorstore, self.bm25, query, k, alpha)
        docs_content = [doc.page_content for doc in top_docs]
        show_context(docs_content)


def 解析参数():
    """
    解析命令行参数。

    返回：
        args: 解析后的参数。
    """
    import argparse
    parser = argparse.ArgumentParser(description="融合检索RAG脚本")
    parser.add_argument('--path', type=str, default="../data/Understanding_Climate_Change.pdf",
                        help='PDF文件的路径。')
    parser.add_argument('--chunk_size', type=int, default=1000, help='每个文本块的大小。')
    parser.add_argument('--chunk_overlap', type=int, default=200, help='连续块之间的重叠量。')
    parser.add_argument('--query', type=str, default='气候变化对环境的影响是什么？',
                        help='用于检索文档的查询。')
    parser.add_argument('--k', type=int, default=5, help='要检索的文档数量。')
    parser.add_argument('--alpha', type=float, default=0.5, help='向量检索与BM25的权重比。')

    return parser.parse_args()


if __name__ == "__main__":
    args = 解析参数()
    检索器 = 融合检索RAG(路径=args.path, chunk_size=args.chunk_size, chunk_overlap=args.chunk_overlap)
    检索器.运行(query=args.query, k=args.k, alpha=args.alpha)

```
