# 层次索引

**详细实现：**
```python
class HierarchicalIndex:
    def __init__(self, embeddings_model):
        self.embeddings_model = embeddings_model
        self.topic_index = {}
        self.subtopic_index = {}
        self.document_index = {}
        
    def build_index(self, documents: List[Document]):
        # 1. 构建主题层级
        topics = self._extract_topics(documents)
        self._build_topic_index(topics)
        
        # 2. 构建子主题层级
        for topic in topics:
            subtopics = self._extract_subtopics(topic, documents)
            self._build_subtopic_index(topic, subtopics)
            
        # 3. 构建文档层级
        self._build_document_index(documents)
        
    def search(
        self,
        query: str,
        top_k: int = 5
    ) -> List[Document]:
        # 1. 找到相关主题
        topic_scores = self._score_topics(query)
        relevant_topics = self._select_top_topics(topic_scores)
        
        # 2. 在相关主题中搜索子主题
        subtopic_results = []
        for topic_id in relevant_topics:
            subtopic_scores = self._score_subtopics(query, topic_id)
            relevant_subtopics = self._select_top_subtopics(subtopic_scores)
            subtopic_results.extend(relevant_subtopics)
            
        # 3. 在相关子主题中搜索文档
        final_results = []
        for topic_id, subtopic_id in subtopic_results:
            docs = self._search_leaf_documents(
                query, topic_id, subtopic_id)
            final_results.extend(docs)
            
        return self._rank_and_deduplicate(final_results)[:top_k]
```

**优化策略：**
1. 索引构建优化
   ```python
   class IndexOptimizer:
       def optimize_clustering(
           self, 
           documents: List[Document]
       ) -> Dict[str, List[Document]]:
           # 使用层次聚类
           clustering = AgglomerativeClustering(
               n_clusters=None,
               distance_threshold=0.5
           )
           
           # 计算文档嵌入
           embeddings = self.embeddings.embed_documents(
               [doc.page_content for doc in documents]
           )
           
           # 执行聚类
           clusters = clustering.fit_predict(embeddings)
           
           # 组织聚类结果
           clustered_docs = defaultdict(list)
           for doc, cluster_id in zip(documents, clusters):
               clustered_docs[cluster_id].append(doc)
               
           return dict(clustered_docs)
   ```

2. 检索性能优化
   ```python
   class SearchOptimizer:
       def __init__(self):
           self.cache = LRUCache(maxsize=1000)
           
       def search_with_cache(
           self, 
           query: str,
           index: HierarchicalIndex
       ) -> List[Document]:
           cache_key = self._generate_cache_key(query)
           
           if cache_key in self.cache:
               return self.cache[cache_key]
           
           results = index.search(query)
           self.cache[cache_key] = results
           return results
           
       def _generate_cache_key(self, query: str) -> str:
           # 生成规范化的缓存键
           normalized_query = self._normalize_query(query)
           return hashlib.md5(normalized_query.encode()).hexdigest()
   ``` 