# 迭代检索

一户话总结： 根据结果确定是否重复查询以达到准确的结果


用户输入问题 -> 查询重构 -> 检索相关文档 -> 文档排序和筛选 -> 上下文拼接 -> LLM生成回答 -> 输出答案

- 将检索到的文档拼接成一个上下文段落。
- 与原始问题一起输入到 LLM。

- LLM 根据上下文生成最终回答。
- 如果检索的上下文不足以回答问题，可以提示用户提供更多信息，或通过迭代生成补充查询。

```python
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

# 准备文档集合
documents = [
    "太阳是太阳系中心的恒星，它的质量约为木星的1000倍。",
    "水星是太阳系最内层也是最小的行星，表面温度变化很大。",
    "金星是太阳系中第二颗行星，被称为地球的姐妹星。",
    "地球是太阳系中第三颗行星，是目前已知唯一孕育生命的星球。",
    "火星是太阳系中第四颗行星，表面有红色氧化铁，被称为红色星球。",
    "木星是太阳系最大的行星，它的大红斑是一个持续了至少400年的风暴。",
    "土星以其显著的环系统闻名，是太阳系中第二大的行星。",
    "天王星和海王星是太阳系的冰巨星，它们的大气主要由氢、氦和甲烷组成。"
]

# 初始化必要组件
splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=50)
docs = splitter.create_documents(documents)
embeddings = OpenAIEmbeddings()
vector_store = FAISS.from_documents(docs, embeddings)
llm = ChatOpenAI(temperature=0.3, model_name="gpt-4")

def create_iterative_chain():
    """创建迭代检索链"""
    # 创建评估提示模板
    evaluation_prompt = ChatPromptTemplate.from_template("""
基于以下上下文信息回答问题。如果信息不足，生成新的查询来获取更多信息。

<context>
{context}
</context>

当前问题: {input}

请按以下格式回复：
1. 如果当前信息足够回答问题，以"SUFFICIENT:"开头，然后给出完整答案
2. 如果需要更多信息，以"QUERY:"开头，然后给出新的查询

注意：
- 新查询应该针对性地获取缺失的关键信息
- 确保查询与原始问题相关
- 考虑已有信息，避免重复查询
""")
    
    # 创建文档链
    document_chain = create_stuff_documents_chain(llm, evaluation_prompt)
    
    # 创建检索器
    retriever = vector_store.as_retriever(search_kwargs={"k": 2})
    
    # 创建检索链
    return create_retrieval_chain(retriever, document_chain)

def enhanced_iterative_retrieval(query, max_rounds=3):
    """
    增强版迭代检索函数
    :param query: 初始查询
    :param max_rounds: 最大迭代轮次
    :return: (最终答案, 检索历史)
    """
    chain = create_iterative_chain()
    current_query = query
    retrieval_history = []
    
    print(f"📝 初始问题: {query}")
    
    for round_num in range(max_rounds):
        print(f"\n🔄 第 {round_num + 1} 轮检索:")
        print(f"当前查询: {current_query}")
        
        # 执行检索
        response = chain.invoke({"input": current_query})
        answer = response["answer"]
        
        # 记录本轮检索
        retrieval_history.append({
            "round": round_num + 1,
            "query": current_query,
            "response": answer
        })
        
        print(f"LLM响应: {answer}")
        
        # 检查是否已获得足够信息
        if answer.startswith("SUFFICIENT:"):
            return answer[11:].strip(), retrieval_history
        
        # 提取新的查询
        if answer.startswith("QUERY:"):
            current_query = answer[6:].strip()
        else:
            return "无法生成有效的补充查询", retrieval_history
    
    return "达到最大迭代次数限制", retrieval_history

def run_example_query(query):
    """运行示例查询并展示结果"""
    print(f"\n{'='*50}")
    print(f"🔍 测试查询: {query}")
    
    answer, history = enhanced_iterative_retrieval(query)
    
    print(f"\n📊 检索过程摘要:")
    for round_data in history:
        print(f"\n轮次 {round_data['round']}:")
        print(f"查询: {round_data['query']}")
        print(f"响应: {round_data['response']}")
    
    print(f"\n✨ 最终答案: {answer}")
    print(f"{'='*50}\n")

# 运行示例查询
example_queries = [
    "木星有什么特别之处？",
    "太阳系中最大的两个行星是什么，它们有什么特点？",
    "哪些行星被称为冰巨星，它们的特点是什么？"
]

for query in example_queries:
    run_example_query(query)
``` 

- [官方例子](https://python.langchain.com/docs/integrations/vectorstores/aperturedb/)